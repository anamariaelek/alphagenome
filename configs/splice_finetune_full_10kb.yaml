# Configuration for fine-tuning AlphaGenome on splice site data

seed: 1950
device: 'cuda'
gpu_mem_fraction: 0.5
num_threads: 1  # Number of CPU threads for data loading and processing
num_interop_threads: 1  # Number of threads for PyTorch inter-op parallelism
num_workers: 12

# Training parameters
seq_len: 10240  # Must be power of 2  (e.g. 4096, 8192, 10240, ... , 49152, 51150)
batch_size: 16
epochs: 50
lr: 1.0e-4
validation_fraction: 0.2  # Fraction of training data to use for validation

# Data paths
data_dir: '/home/elek/sds/sd17d003/Anamaria/splicevo/data/splits_full_10kb/mouse_human/train'
max_donor_sites: 50
max_acceptor_sites: 50

# Output directory
output_dir: '/home/elek/sds/sd17d003/Anamaria/alphagenome_pytorch/full_10kb/mouse_human/'
model_name: 'finetune'  # Name for the saved model file (without .pt extension)

# Pretrained weights
load_pretrained: true
pretrained_model_version: 'all_folds' # all_folds or fold-0, fold-1, fold-2, fold-3, fold-4
freeze_backbone: false  # Set to true to only train heads
heads_to_train: ['splice_sites_classification', 'splice_sites_usage']  # Specify which heads to train e.g. 'splice_sites_classification', 'splice_sites_usage', 'splice_sites_junction'

# Model architecture (use defaults or customize)
model:
  num_organisms: 2  # human + mouse
  # dims: [768, 896, 1024, 1152, 1280, 1408, 1536]  # uncomment to customize
  # basepairs: 4
  # dna_embed_width: 15
  heads_cfg:
    human:
      num_tracks_1bp: 0
      num_tracks_128bp: 0
      num_tracks_contacts: 0
      num_splicing_contexts: 62 ### Hardcoded (full 62, adult 16, small 7)
    mouse:
      num_tracks_1bp: 0
      num_tracks_128bp: 0
      num_tracks_contacts: 0
      num_splicing_contexts: 93 ### Hardcoded (full 93, adult 34, small 8)