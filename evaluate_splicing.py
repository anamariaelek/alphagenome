"""
Evaluate predictions from parquet files.
Works with predictions generated by predict_splicing.py and predict_splicing_pretrained.py
"""

import numpy as np
import pandas as pd
import json
from pathlib import Path
import yaml
from sklearn.metrics import precision_recall_curve, auc
import matplotlib.pyplot as plt
import time

def load_predictions(predictions_dir, model_name):
    """Load predictions from HDF5 and parquet files.
    
    Args:
        predictions_dir: Path to directory containing prediction files
        model_name: Name of the model (used in filenames)
        
    Returns:
        Dictionary with labels and usage data
    """
    import h5py
    
    predictions_dir = Path(predictions_dir)
    
    print(f"Loading predictions from {predictions_dir}...")
    print(f"  Model: {model_name}")
    
    # Load labels from HDF5 (much faster than npz for large files)
    labels_data = {}
    for organism in ['human', 'mouse']:
        # Try HDF5 first (new format)
        labels_file = predictions_dir / f'{model_name}_{organism}_labels.h5'
        if labels_file.exists():
            with h5py.File(labels_file, 'r') as f:
                labels_data[organism] = {
                    'sample_idx': f['sample_idx'][:],  # Load into memory
                    'true_labels': f['true_labels'][:],  # (N, seq_len)
                    'probs': f['probs'][:]  # (N, seq_len, 5)
                }
                print(f"  Loaded {organism} labels (HDF5): {len(labels_data[organism]['sample_idx'])} samples")
        else:
            # Fallback to npz (old format)
            labels_file_npz = predictions_dir / f'{model_name}_{organism}_labels.npz'
            if labels_file_npz.exists():
                data = np.load(labels_file_npz)
                labels_data[organism] = {
                    'sample_idx': data['sample_idx'],
                    'true_labels': data['true_labels'],  # (N, seq_len)
                    'probs': data['probs']  # (N, seq_len, 5)
                }
                print(f"  Loaded {organism} labels (npz): {len(data['sample_idx'])} samples")
    
    # Load usage from parquet
    usage_file = predictions_dir / f'{model_name}_usage.parquet'
    usage_df = pd.read_parquet(usage_file) if usage_file.exists() else None
    
    if usage_df is not None:
        print(f"  Loaded usage: {len(usage_df)} rows")
    
    return {
        'labels': labels_data,
        'usage': usage_df
    }

# Start timing
start_time_total = time.time()
print("Starting evaluation...")

# Load config for finetuned model
config_file = '/home/elek/projects/alphagenome_pytorch/configs/splice_finetune_adult_10kb.yaml'
with open(config_file, 'r') as f:
    config = yaml.safe_load(f)

output_dir = config.get('output_dir', './outputs')
model_name = config.get('model_name', 'alphagenome_finetuned')
predictions_dir = Path(output_dir) / 'predictions'

# Uncomment for pretrained model evaluation
output_dir = "outputs/predictions/pretrained/adult_mouse_human_10kb"
model_name = "pretrained_model"
predictions_dir = Path(output_dir)

# Load predictions
start_time_load = time.time()
data = load_predictions(predictions_dir, model_name)
load_time = time.time() - start_time_load
print(f"\nData loading time: {load_time:.2f} seconds")
labels_data = data['labels']
usage_df = data['usage']

print(f"\nPredictions loaded!")
print(f"  Organisms: {list(labels_data.keys())}")

# Class labels and colors
class_labels = {0: 'donor +', 1: 'acceptor +', 2: 'donor -', 3: 'acceptor -', 4: 'no splice site'}
class_colors = {0: '#ff7f00', 1: '#33a02c', 2: '#fdbf6f', 3: '#b2df8a', 4: '#1f78b4'}

# Evaluate splice site classification for each species separately
start_time_labels = time.time()
for org_name in labels_data.keys():

    print(f"\nEvaluating {org_name} splice site classification")
    
    splice_logits_flat =  labels_data[org_name]['probs'].reshape(-1, labels_data[org_name]['probs'].shape[-1])
    splice_labels_flat = labels_data[org_name]['true_labels'] .reshape(-1)

    from sklearn.metrics import precision_recall_curve, auc

    plt.figure(figsize=(5, 4))

    for i in range(5):
        color = class_colors[i]
        label = class_labels[i]
        
        class_idx = splice_labels_flat == i
        y_true = np.zeros_like(splice_labels_flat)
        y_true[class_idx] = 1
        y_scores = splice_logits_flat[:, i]

        if len(y_true) > 0 and y_true.sum() > 0:
            precision, recall, _ = precision_recall_curve(y_true, y_scores)
            pr_auc = auc(recall, precision)
            print(f"  {label}: AUC={pr_auc:.3f} (Positives: {y_true.sum()})")
            plt.plot(recall, precision, label=f"{label} (AUC={pr_auc:.2f})", color=color)
        else:
            print(f"  Warning: No positive samples for {label}") 

    plt.xlabel("Recall")
    plt.ylabel("Precision")
    plt.title(f"PR Curve - {org_name.capitalize()} Splice Site Classification")
    plt.legend()
    plt.grid()
    plt.tight_layout()
    plt.savefig(predictions_dir / f'{model_name}_{org_name}_pr_curve.png', dpi=150)
    print(f"  Saved plot: {predictions_dir / f'{model_name}_{org_name}_pr_curve.png'}")
    plt.close()

    # Plot boxplot of predicted probabilities for each class at true classes
    fig, axes = plt.subplots(2, 2, figsize=(6, 6))
    axes = axes.flatten()

    titles = ["Donor + (label=0)", "Acceptor + (label=1)", "Donor - (label=2)", "Acceptor - (label=3)"]
    true_labels = [0, 1, 2, 3]

    for idx, (ax, title, true_label) in enumerate(zip(axes, titles, true_labels)):
        mask = splice_labels_flat == true_label
        if mask.any():
            probs_for_label = labels_data[org_name]['probs'][mask]
            box_data = [probs_for_label[:, i] for i in range(5)]
            ax.boxplot(box_data, tick_labels=[f'{i}' for i in range(5)])
            ax.set_title(title)
            ax.set_ylabel("Predicted probability")
            ax.set_xlabel("Predicted class")
            ax.grid(True, alpha=0.3)

    plt.suptitle(f"{org_name.capitalize()} - Predicted Probabilities by True Label", fontsize=14)
    plt.tight_layout()
    plt.savefig(predictions_dir / f'{model_name}_{org_name}_boxplots.png', dpi=150)
    print(f"  Saved plot: {predictions_dir / f'{model_name}_{org_name}_boxplots.png'}")
    plt.close()

labels_time = time.time() - start_time_labels
print(f"\nLabel evaluation time: {labels_time:.2f} seconds")

# Evaluate splice usage predictions for each species separately
start_time_usage = time.time()
for org_name in usage_df['organism'].unique():

    print(f"Evaluating {org_name} splice usage prediction")
    
    # Filter for this organism
    org_usage_df = usage_df[usage_df['organism'] == org_name].copy()
    
    print(f"Total usage predictions: {len(org_usage_df)}")
    print(f"Unique splice sites: {org_usage_df[['sample_idx', 'position']].drop_duplicates().shape[0]}")
    print(f"Conditions: {org_usage_df['condition_name'].unique().tolist()}")
    
    # Get true and predicted usage
    usage_true = org_usage_df['true_usage'].values
    usage_pred = org_usage_df['pred_usage'].values
    
    # Group true usage in bins: 0 - 0.2 - 0.5 - 0.8 - 1.0
    usage_true_bins = np.zeros_like(usage_true, dtype=int)
    usage_true_bins[usage_true < 0.2] = 0
    usage_true_bins[(usage_true >= 0.2) & (usage_true < 0.5)] = 1
    usage_true_bins[(usage_true >= 0.5) & (usage_true < 0.8)] = 2
    usage_true_bins[usage_true >= 0.8] = 3
    
    # Count number of values in each bin
    print("\nTrue usage distribution by bins:")
    for i in range(4):
        count = np.sum(usage_true_bins == i)
        bin_labels = ['0-0.2', '0.2-0.5', '0.5-0.8', '0.8-1.0']
        print(f"  {bin_labels[i]}: {count} values")
    
    # Plot boxplot of predicted usage for each true usage bin
    plt.figure(figsize=(5, 5))
    plt.title(f"{org_name.capitalize()} - Predicted by True Usage Bins")
    usage_pred_bins = [usage_pred[usage_true_bins == i] for i in range(4)]
    plt.boxplot(usage_pred_bins, tick_labels=['0-0.2', '0.2-0.5', '0.5-0.8', '0.8-1.0'])
    plt.ylabel("Predicted splice usage")
    plt.xlabel("True splice usage bins")
    plt.ylim(0, 1)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(predictions_dir / f'{model_name}_{org_name}_usage_bins.png', dpi=150)
    print(f"  Saved plot: {predictions_dir / f'{model_name}_{org_name}_usage_bins.png'}")
    plt.close()
    
    # Calculate correlation between true and predicted usage at splice sites
    correlation = np.corrcoef(usage_true, usage_pred)[0, 1]
    print(f"\nCorrelation: {correlation:.3f}")
    
    # Plot scatter plot of predicted usage vs true usage
    plt.figure(figsize=(5, 5))
    plt.title(f"{org_name.capitalize()} - Predicted vs True Usage")
    plt.scatter(usage_true, usage_pred, alpha=0.5, s=10)
    plt.xlabel("True splice usage")
    plt.ylabel("Predicted splice usage")
    plt.xlim(0, 1)
    plt.ylim(0, 1)
    plt.text(0.05, 0.95, f"r = {correlation:.3f}", transform=plt.gca().transAxes, 
             verticalalignment='top', fontsize=12)
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(predictions_dir / f'{model_name}_{org_name}_usage_scatter.png', dpi=150)
    print(f"  Saved plot: {predictions_dir / f'{model_name}_{org_name}_usage_scatter.png'}")
    plt.close()
    
    # Plot per-condition correlation
    conditions = org_usage_df['condition_name'].unique()
    if len(conditions) > 1:
        fig, axes = plt.subplots(1, len(conditions), figsize=(5 * len(conditions), 5))
        if len(conditions) == 1:
            axes = [axes]
        
        for idx, cond_name in enumerate(conditions):
            cond_df = org_usage_df[org_usage_df['condition_name'] == cond_name]
            true_vals = cond_df['true_usage'].values
            pred_vals = cond_df['pred_usage'].values
            
            corr = np.corrcoef(true_vals, pred_vals)[0, 1]
            
            axes[idx].scatter(true_vals, pred_vals, alpha=0.5, s=10)
            axes[idx].set_xlabel("True usage")
            axes[idx].set_ylabel("Predicted usage")
            axes[idx].set_xlim(0, 1)
            axes[idx].set_ylim(0, 1)
            axes[idx].set_title(f"{cond_name}\nr = {corr:.3f}")
            axes[idx].grid(True, alpha=0.3)
        
        plt.suptitle(f"{org_name.capitalize()} - Per-Condition Usage Predictions")
        plt.tight_layout()
        plt.savefig(predictions_dir / f'{model_name}_{org_name}_usage_per_condition.png', dpi=150)
        print(f"  Saved plot: {predictions_dir / f'{model_name}_{org_name}_usage_per_condition.png'}")
        plt.close()

usage_time = time.time() - start_time_usage
print(f"\nUsage evaluation time: {usage_time:.2f} seconds")

total_time = time.time() - start_time_total

print("Evaluation complete! All plots saved to:", predictions_dir)
print(f"\nTiming Summary:")
print(f"  Data loading:      {load_time:7.2f} seconds")
print(f"  Label evaluation:  {labels_time:7.2f} seconds")
print(f"  Usage evaluation:  {usage_time:7.2f} seconds")
print(f"  {'â”€'*40}")
print(f"  Total time:        {total_time:7.2f} seconds")

